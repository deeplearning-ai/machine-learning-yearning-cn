---
title: 开发集和测试集应该有多大？
permalink: /docs/ch07/
---

开发集的规模应该大到足以区分出你所尝试的不同算法间的性能差异。例如，如果分类器 A 的准确率为 90.0% ，而分类器 B 的准确率为 90.1% ，那么仅有 100 个样本的开发集将无法检测出这 0.1% 的差异。相比我所遇到的机器学习问题，一个样本容量为 100 的开发集的规模是非常小的。通常来说，开发集的规模应该在 1,000 到 10,000 个样本数据之间，而当开发集样本容量为 10,000 时，你将很有可能检测到 0.1% 的性能提升。

> 从理论上说，还可以检测算法的变化是否会在开发集上造成统计学意义上的显著差异。 然而在实践中，大多数团队并不会为此而烦恼（除非他们正在发表学术研究论文），而且我通常在检测过程中并没有发现统计显著性检验有多少作用。

像广告服务、网络搜索和产品推荐等较为成熟且关键的应用领域，我曾见过一些团队非常积极地去改进算法性能，哪怕仅有 0.01% 的提升，因为这将直接影响到公司的利润。在这种情况下，开发集规模可能远超过 10,000 个样本，从而有利于检测到那些不易察觉的效果提升。

那么测试集的大小又该如何确定呢？它的规模应该大到使你能够对整体系统的性能进行一个高度可信的评估。一种常见的启发式策略是将整体 30% 的数据用作测试集，这适用于数据量规模一般的情况（比如 100 至 10,000 个样本）。但是在大数据时代，我们所面临的机器学习问题的样本数量有时会超过 10 个亿，即使开发集和测试集中样本的绝对数量一直在增长，可总体上分配给开发集和测试集的数据比例正在不断降低。可以看出，我们并不需要远超过评估算法性能所需的开发集和测试集规模，也即是说开发集和测试集的规模并不是越大越好。